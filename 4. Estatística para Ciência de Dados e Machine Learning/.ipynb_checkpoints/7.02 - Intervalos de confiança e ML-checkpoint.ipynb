{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intervalos de confiança e classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as srn\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import math\n",
    "srn.set()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Bases de dados/credit_data.csv')\n",
    "dataset.dropna(inplace=True)\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 1:4].values\n",
    "y = dataset.iloc[:, 4].values\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_naive_bayes_cv = []\n",
    "resultados_naive_bayes_cv_300 = []\n",
    "resultados_logistica_cv = []\n",
    "resultados_logistica_cv_300 = []\n",
    "resultados_forest_cv = []\n",
    "resultados_forest_cv_300 = []\n",
    "\n",
    "for i in range(30):\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=i)\n",
    "    \n",
    "    naive_bayes = GaussianNB()\n",
    "    scores = cross_val_score(naive_bayes, X, y, cv=kfold)\n",
    "    resultados_naive_bayes_cv_300.append(scores)\n",
    "    resultados_naive_bayes_cv.append(scores.mean())\n",
    "    \n",
    "    logistic = LogisticRegression()\n",
    "    scores = cross_val_score(logistic, X, y, cv=kfold)\n",
    "    resultados_logistica_cv_300.append(scores)\n",
    "    resultados_logistica_cv.append(scores.mean())\n",
    "    \n",
    "    forest = RandomForestClassifier()\n",
    "    scores = cross_val_score(forest, X, y, cv=kfold)\n",
    "    resultados_forest_cv_300.append(scores)\n",
    "    resultados_forest_cv.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_naive_bayes_cv = np.array( resultados_naive_bayes_cv)\n",
    "resultados_naive_bayes_cv_300 = np.array(np.asarray(resultados_naive_bayes_cv_300).reshape(-1))\n",
    "resultados_logistica_cv = np.array(resultados_logistica_cv)\n",
    "resultados_logistica_cv_300 = np.array(np.asarray(resultados_logistica_cv_300).reshape(-1))\n",
    "resultados_forest_cv = np.array(resultados_forest_cv)\n",
    "resultados_forest_cv_300 = np.array(np.asarray(resultados_forest_cv_300).reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, figsize=(14,8))\n",
    "srn.histplot(resultados_naive_bayes_cv, ax=ax[0,0]);\n",
    "srn.histplot(resultados_naive_bayes_cv_300, ax=ax[1,0]);\n",
    "srn.histplot(resultados_logistica_cv, ax=ax[0,1]);\n",
    "srn.histplot(resultados_logistica_cv_300, ax=ax[1,1] );\n",
    "srn.histplot(resultados_forest_cv, ax=ax[0,2]);\n",
    "srn.histplot(resultados_forest_cv_300, ax=ax[1,2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Média: \\n')\n",
    "print(f'Naive-bayes: {resultados_naive_bayes_cv.mean()}')\n",
    "print(f'Regressão Logística: {resultados_logistica_cv.mean()}')\n",
    "print(f'Random Forest: {resultados_forest_cv.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Variação dos resultados: \\n')\n",
    "print(f'Naive-bayes: {stats.variation(resultados_naive_bayes_cv)*100}')\n",
    "print(f'Regressão Logística: {stats.variation(resultados_logistica_cv)*100}')\n",
    "print(f'Random Forest: {stats.variation(resultados_forest_cv)*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intervalos de confiança"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t, norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervalos_nb_t = t.interval(0.956,\n",
    "                             len(resultados_naive_bayes_cv)-1,\n",
    "                             resultados_naive_bayes_cv.mean(), \n",
    "                             stats.sem(resultados_naive_bayes_cv, ddof=0))\n",
    "intervalos_nb_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Margem de erro\n",
    "abs(resultados_naive_bayes_cv.mean() - intervalos_nb_t[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervalos_nb_n = norm.interval(0.956,\n",
    "                             resultados_naive_bayes_cv.mean(), \n",
    "                             stats.sem(resultados_naive_bayes_cv, ddof=0))\n",
    "intervalos_nb_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Margem de erro\n",
    "abs(resultados_naive_bayes_cv.mean() - intervalos_nb_n[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervalos_rl_t = t.interval(0.956,\n",
    "                             len(resultados_logistica_cv)-1,\n",
    "                             resultados_logistica_cv.mean(), \n",
    "                             stats.sem(resultados_logistica_cv, ddof=0))\n",
    "intervalos_rl_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Margem de erro\n",
    "abs(resultados_logistica_cv.mean() - intervalos_rl_t[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervalos_rl_n = norm.interval(0.95,\n",
    "                             resultados_logistica_cv.mean(), \n",
    "                             stats.sem(resultados_logistica_cv, ddof=0))\n",
    "intervalos_rl_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Margem de erro\n",
    "abs(resultados_logistica_cv.mean() - intervalos_rl_n[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervalos_rf_t = t.interval(0.95,\n",
    "                             len(resultados_forest_cv)-1,\n",
    "                             resultados_forest_cv.mean(), \n",
    "                             stats.sem(resultados_forest_cv, ddof=0))\n",
    "intervalos_rf_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Margem de erro\n",
    "abs(resultados_forest_cv.mean() - intervalos_rf_t[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervalos_rf_n = norm.interval(0.95,\n",
    "                             resultados_forest_cv.mean(), \n",
    "                             stats.sem(resultados_forest_cv, ddof=0))\n",
    "intervalos_rf_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Margem de erro\n",
    "abs(resultados_forest_cv.mean() - intervalos_rf_n[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos 95% de confiança de que a média de acertos do Random Forest está no intervalo entre 98.65-98.66 e 98.77-98.78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "random_forest = RandomForestClassifier()\n",
    "socre = cross_val_score(random_forest, X, y, cv=kfold)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já mostrou uma valor fora do intervalo!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste de hipótese Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = np.array([126. , 129.5, 133. , 133. , 136.5, 136.5, 140. , 140. , 140. ,\n",
    "                  140. , 143.5, 143.5, 143.5, 143.5, 143.5, 143.5, 147. , 147. ,\n",
    "                  147. , 147. , 147. , 147. , 147. , 150.5, 150.5, 150.5, 150.5,\n",
    "                  150.5, 150.5, 150.5, 150.5, 154. , 154. , 154. , 154. , 154. ,\n",
    "                  154. , 154. , 154. , 154. , 157.5, 157.5, 157.5, 157.5, 157.5,\n",
    "                  157.5, 157.5, 157.5, 157.5, 157.5, 161. , 161. , 161. , 161. ,\n",
    "                  161. , 161. , 161. , 161. , 161. , 161. , 164.5, 164.5, 164.5,\n",
    "                  164.5, 164.5, 164.5, 164.5, 164.5, 164.5, 168. , 168. , 168. ,\n",
    "                  168. , 168. , 168. , 168. , 168. , 171.5, 171.5, 171.5, 171.5,\n",
    "                  171.5, 171.5, 171.5, 175. , 175. , 175. , 175. , 175. , 175. ,\n",
    "                  178.5, 178.5, 178.5, 178.5, 182. , 182. , 185.5, 185.5, 189., 192.5])\n",
    "print(len(dados))\n",
    "#dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0_media = np.mean(dados)\n",
    "h0_desvio_padrao = np.std(dados)\n",
    "h0_media, h0_desvio_padrao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_novos = dados * 1.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_media = np.mean(dados_novos)\n",
    "h1_desvio_padrao = np.std(dados_novos)\n",
    "h1_media, h1_desvio_padrao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H1_n = len(dados_novos)\n",
    "H0_n = len(dados)\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = (h1_media - h0_media) / (h1_desvio_padrao / math.sqrt(H1_n))\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = norm.cdf(Z)\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 1 - Z\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if p < alpha:\n",
    "    print('Rejeitar hipótese nula')\n",
    "else:\n",
    "    print('Rejeita hipótese alternativa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste com statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.weightstats import ztest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, p = ztest(dados, \n",
    "             dados_novos, \n",
    "             value = h1_media - h0_media, \n",
    "             alternative='larger')\n",
    "p = 1 - p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if p < alpha:\n",
    "    print('Rejeitar hipótese nula')\n",
    "else:\n",
    "    print('Rejeita hipótese alternativa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício - T student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = np.array([149. , 160., 147., 189., 175., 168., 156., 160., 152.])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df * 1.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, p = ttest_rel(df, df_2)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "if p < alpha:\n",
    "    print('Rejeitar hipótese nula')\n",
    "else:\n",
    "    print('Rejeita hipótese alternativa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qui Quadrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela = np.array([[30, 20], [22, 29]])\n",
    "df_tabela = pd.DataFrame(tabela, \n",
    "             columns=['Visão computacional', 'Algoritmos de busca'], \n",
    "             index=['Homens', \"Mulheres\"])\n",
    "print(df_tabela.shape)\n",
    "df_tabela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = chi2_contingency(tabela)[1]\n",
    "freq_esperada = chi2_contingency(tabela)[3]\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "if p <= alpha:\n",
    "    print('Rejeitar hipótese nula')\n",
    "else:\n",
    "    print('Rejeitar hipótese alternativa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou seja, não há diferença estatística significativa nesse conjunto de dados (eles não dizem nada)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qui quadrado - seleção de atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFdr\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Bases de dados/ad.data', header=None)\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 0:1558].values\n",
    "y = dataset.iloc[:, 1558].values\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive1 = GaussianNB()\n",
    "naive1.fit(X, y)\n",
    "previsoes1 = naive1.predict(X)\n",
    "accuracy_score(previsoes1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selecao = SelectFdr(chi2, alpha=0.01)\n",
    "X_novo = selecao.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_novo.shape, y.shape   # reduziu X de 1558 para 433 atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selecao.pvalues_, len(selecao.pvalues_), np.sum(selecao.pvalues_ <= 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas = selecao.get_support()\n",
    "print(colunas.shape)\n",
    "indices = np.where(colunas == True)\n",
    "len(indices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive2 = GaussianNB()\n",
    "naive2.fit(X_novo, y)\n",
    "previsoes2 = naive2.predict(X_novo)\n",
    "accuracy_score(previsoes2, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melhorou!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA - Análise de variância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
